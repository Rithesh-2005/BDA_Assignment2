{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72109c39",
   "metadata": {},
   "source": [
    "The RandomForestClassifier in PySpark is a powerful ensemble learning method used for classification tasks. It operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees. This approach leverages the wisdom of the crowd, combining the predictions of individual trees to make more accurate and robust classifications. Random Forests are known for their ability to handle high-dimensional data with numerous features, and they often achieve excellent performance without extensive hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e85ad",
   "metadata": {},
   "source": [
    "About the dataset:\n",
    "\n",
    "\n",
    "*   Source: The digits dataset is a built-in dataset in the scikit-learn library. You loaded it using from sklearn.datasets import load_digits and digits = load_digits().\n",
    "*   Content: It's a collection of handwritten digits (0-9) represented as 8x8 grayscale images. Each image is flattened into a 64-dimensional feature vector.\n",
    "*   Size: The dataset contains 1797 samples.\n",
    "*  Task: It's typically used for classification tasks, where the goal is to predict the digit in an image based on its pixel values.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c294bb1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "\n",
    "#Start Spark session\n",
    "spark = SparkSession.builder.appName(\"DigitsClassification\").getOrCreate()\n",
    "\n",
    "#Load digits dataset using sklearn\n",
    "digits = load_digits()\n",
    "data_pd = pd.DataFrame(data=digits.data, columns=[f\"pixel_{i}\" for i in range(digits.data.shape[1])])\n",
    "data_pd[\"label\"] = digits.target\n",
    "\n",
    "#Convert to Spark DataFrame\n",
    "data = spark.createDataFrame(data_pd)\n",
    "\n",
    "#Feature vector assembly\n",
    "feature_cols = [col for col in data.columns if col.startswith(\"pixel_\")]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data = assembler.transform(data).select(\"features\", \"label\")\n",
    "\n",
    "#Split into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "#Train Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "#Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "#Evaluate model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"âœ… Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: Show confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to pandas for plotting\n",
    "preds_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "cm = confusion_matrix(preds_pd[\"label\"], preds_pd[\"prediction\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Digits Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaff4b5",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a290c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "correct = preds_pd[preds_pd[\"label\"] == preds_pd[\"prediction\"]]\n",
    "class_counts = preds_pd[\"label\"].value_counts().sort_index()\n",
    "correct_counts = correct[\"label\"].value_counts().sort_index()\n",
    "accuracy_per_class = (correct_counts / class_counts).fillna(0)\n",
    "\n",
    "sns.barplot(x=accuracy_per_class.index, y=accuracy_per_class.values)\n",
    "plt.xlabel(\"Digit\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per Digit Class\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be2d10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "sample = preds_pd.sample(10, random_state=42)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "  idx = sample.index[i]\n",
    "  img = digits.images[idx]\n",
    "  pred = sample.iloc[i][\"prediction\"]\n",
    "  true = sample.iloc[i][\"label\"]\n",
    "  ax.imshow(img, cmap=\"gray\")\n",
    "  ax.set_title(f\"Pred: {int(pred)}, True: {int(true)}\", fontsize=10)\n",
    "  ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Sample Predictions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
