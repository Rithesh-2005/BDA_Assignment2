{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74105ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Start Spark session\n",
    "spark = SparkSession.builder.appName(\"BlobsClustering\").getOrCreate()\n",
    "\n",
    "#Generate synthetic dataset using make_blobs()\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)\n",
    "df_pd = pd.DataFrame(X, columns=[\"x\", \"y\"])\n",
    "df_pd[\"label\"] = y_true # true labels (for visualization only)\n",
    "\n",
    "#Convert to Spark DataFrame\n",
    "df = spark.createDataFrame(df_pd[[\"x\", \"y\"]])\n",
    "\n",
    "#Assemble features into vector\n",
    "vec_assembler = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol=\"features\")\n",
    "df_features = vec_assembler.transform(df)\n",
    "\n",
    "#Train KMeans model\n",
    "kmeans = KMeans(k=4, seed=1, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "model = kmeans.fit(df_features)\n",
    "\n",
    "#Predict clusters\n",
    "predictions = model.transform(df_features)\n",
    "\n",
    "#Convert back to Pandas for visualization\n",
    "preds_pd = predictions.select(\"x\", \"y\", \"cluster\").toPandas()\n",
    "\n",
    "#Plot the clustered points\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=preds_pd, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"Set2\", s=60)\n",
    "plt.title(\"KMeans Clustering (k=4) on Synthetic Blob Data\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Plot original labels for comparison\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y_true, palette=\"Set1\", s=60)\n",
    "plt.title(\"Original Labels (for reference only)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(title=\"True Label\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7f575",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Elbow plot to find optimal K-value\n",
    "errors = []\n",
    "for k in range(2, 10):\n",
    "  km = KMeans(k=k, seed=1, featuresCol=\"features\")\n",
    "  model_k = km.fit(df_features)\n",
    "  errors.append(model_k.summary.trainingCost)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(2, 10), errors, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Within Set Sum of Squared Errors (WSSSE)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
